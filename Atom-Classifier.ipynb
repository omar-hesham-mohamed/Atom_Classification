{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task 1","metadata":{}},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Balance classes in dataset","metadata":{}},{"cell_type":"code","source":"columns = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', \n           'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n\ndata = pd.read_csv('/kaggle/input/telescope-data/telescope_data.csv', names=columns) # Dataset loaded as pandas dataframe\n\ngamma = data[data['class'] == 'g']\nhadron = data[data['class'] == 'h']\n\ngamma_balanced = gamma.sample(n=len(hadron), random_state=42) # random_state gives the randomness a fixed seed\n\nbalanced_data = pd.concat([gamma_balanced, hadron])\n\nbalanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True) # Shuffle the dataset since we ordered it, then reset the indices\n\nX = balanced_data.drop('class', axis=1) # Seperate features from dataset for training\ny = balanced_data['class'].map({'g': 0, 'h': 1}) # Map gamma to 0 and hadron to 1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Splitting the dataset","metadata":{}},{"cell_type":"code","source":"X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42) # X_train is now 70%\n\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) # Both cv and test are now 15%\n\nprint(f\"Training set size: {len(X_train)}\")\nprint(f\"Validation set size: {len(X_val)}\")\nprint(f\"Test set size: {len(X_test)}\") # Just to make sure","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Manual KNN","metadata":{}},{"cell_type":"code","source":"def euclidean_distance(x1, x2):\n    return np.sqrt(np.sum((x1 - x2) ** 2))\n\nclass KNN:\n    def __init__(self, k):\n        self.k = k\n        \n    def fit(self, X, y):\n        self.X_train = X.to_numpy() # Convert dataset to numpy arrays for vector manipulation\n        self.y_train = y.to_numpy()\n        \n    def predict(self, X):\n        X = X.to_numpy()\n        predictions = [self._predict(x) for x in X]\n        return np.array(predictions)\n        \n    def _predict(self, x):\n        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n        \n        k_indices = np.argsort(distances)[:self.k] # Indices of nearest k points\n        k_nearest_labels = [self.y_train[i] for i in k_indices] # Get their labels\n        \n        most_common = Counter(k_nearest_labels).most_common(1) # Get label with most votes\n        return most_common[0][0] # Return winning label\n    \n    def evaluate(self, X, y):\n        X = X.to_numpy()\n        y = y.to_numpy()\n        predictions = self.predict(X)\n        accuracy = np.sum(predictions == y) / len(y)\n        return accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test manual KNN","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler() # Normaliza features for (hopefully) better results\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test)\n\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns) # Return datatype to dataframe\nX_val_scaled = pd.DataFrame(X_val_scaled, columns=X.columns)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n\nk_values = range(1, 20)\nmanual_accuracies = []\n\nfor k in k_values:\n    knn = KNN(k=k)\n    knn.fit(X_train_scaled, y_train)\n    accuracy = knn.evaluate(X_val_scaled, y_val)\n    manual_accuracies.append(accuracy)\n    print(f\"k={k}, Validation Accuracy={accuracy:.4f}\")\n\nbest_k_manual = k_values[np.argmax(manual_accuracies)]\nprint(f\"Best k for manual implementation: {best_k_manual}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# KNN using scikit-learn","metadata":{}},{"cell_type":"code","source":"sklearn_accuracies = []\n\nfor k in k_values:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train_scaled, y_train)\n    y_pred = knn.predict(X_val_scaled)\n    accuracy = accuracy_score(y_val, y_pred)\n    sklearn_accuracies.append(accuracy)\n    print(f\"k={k}, Validation Accuracy={accuracy:.4f}\")\n\nbest_k_sklearn = k_values[np.argmax(sklearn_accuracies)]\nprint(f\"Best k for sklearn implementation: {best_k_sklearn}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot accuracy for each K","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.plot(k_values, manual_accuracies, label='Manual Implementation', marker='o')\nplt.plot(k_values, sklearn_accuracies, label='Scikit-Learn', marker='x')\nplt.xlabel('k Value')\nplt.ylabel('Validation Accuracy')\nplt.title('Validation Accuracy vs. k Value')\nplt.axvline(x=best_k_manual, color='blue', linestyle='--', label=f'Best Manual k={best_k_manual}')\nplt.axvline(x=best_k_sklearn, color='orange', linestyle='--', label=f'Best Sklearn k={best_k_sklearn}')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing models using best K","metadata":{}},{"cell_type":"code","source":"# Manual knn test\nmanual_knn = KNN(k=best_k_manual)\nmanual_knn.fit(X_train_scaled, y_train)\ny_pred_manual = manual_knn.predict(X_test_scaled)\n\n# Sklearn knn test\nsklearn_knn = KNeighborsClassifier(n_neighbors=best_k_sklearn)\nsklearn_knn.fit(X_train_scaled, y_train)\ny_pred_sklearn = sklearn_knn.predict(X_test_scaled)\n\ndef evaluate_model(y_true, y_pred, model_name):\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n    \n    print(f\"\\n{model_name} Evaluation:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(\"Confusion Matrix:\")\n    print(cm)\n\nevaluate_model(y_test, y_pred_manual, \"Manual KNN\")\nevaluate_model(y_test, y_pred_sklearn, \"Scikit-Learn KNN\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}